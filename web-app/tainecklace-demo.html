<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è TaiNecklace - AI Companion</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background-color: #F5F5F5;
            color: #333;
        }
        
        .container {
            max-width: 600px;
            margin: 0 auto;
            background-color: #F5F5F5;
            min-height: 100vh;
        }
        
        .header {
            text-align: center;
            padding: 40px 20px 20px;
            background-color: white;
            margin-bottom: 16px;
        }
        
        .title {
            font-size: 28px;
            font-weight: bold;
            color: #333;
            margin-bottom: 8px;
        }
        
        .subtitle {
            font-size: 16px;
            color: #666;
        }
        
        .warning {
            font-size: 14px;
            color: #FF6B6B;
            font-style: italic;
            margin-top: 8px;
        }
        
        .card {
            background-color: white;
            margin: 16px;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .card-title {
            font-size: 18px;
            font-weight: bold;
            color: #333;
            margin-bottom: 12px;
        }
        
        .status {
            font-size: 16px;
            margin-bottom: 16px;
            font-weight: 500;
        }
        
        .status.connected { color: #4CAF50; }
        .status.disconnected { color: #666; }
        .status.recording { color: #FF6B6B; }
        .status.ready { color: #007AFF; }
        
        .button {
            background-color: #007AFF;
            color: white;
            padding: 14px 20px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            width: 100%;
            margin-bottom: 8px;
        }
        
        .button:hover {
            background-color: #0056b3;
        }
        
        .button:disabled {
            background-color: #E5E5EA;
            color: #999;
            cursor: not-allowed;
        }
        
        .button.record {
            background-color: #4CAF50;
        }
        
        .button.record:hover {
            background-color: #45a049;
        }
        
        .button.stop {
            background-color: #FF6B6B;
        }
        
        .button.stop:hover {
            background-color: #ff5252;
        }
        
        .input {
            width: 100%;
            padding: 12px;
            border: 1px solid #E5E5EA;
            border-radius: 8px;
            font-size: 16px;
            margin-bottom: 12px;
        }
        
        .transcription {
            background-color: #F8F9FA;
            border-radius: 8px;
            padding: 16px;
            max-height: 200px;
            overflow-y: auto;
            border: 1px solid #E5E5EA;
        }
        
        .transcript-text {
            font-size: 16px;
            line-height: 1.5;
            color: #333;
        }
        
        .partial-text {
            color: #666;
            font-style: italic;
        }
        
        .placeholder {
            color: #999;
            font-style: italic;
            text-align: center;
            padding: 20px;
        }
        
        .tabs {
            display: flex;
            background-color: white;
            border-top: 1px solid #E5E5EA;
            position: fixed;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 100%;
            max-width: 600px;
        }
        
        .tab {
            flex: 1;
            padding: 16px;
            text-align: center;
            border: none;
            background: none;
            font-size: 16px;
            color: #666;
            cursor: pointer;
        }
        
        .tab.active {
            color: #007AFF;
            background-color: #F0F8FF;
            font-weight: 600;
        }
        
        .content {
            padding-bottom: 80px;
        }
        
        .conversation-item {
            border-bottom: 1px solid #F0F0F0;
            padding: 12px 0;
        }
        
        .conversation-title {
            font-weight: 600;
            margin-bottom: 4px;
        }
        
        .conversation-date {
            font-size: 12px;
            color: #666;
            margin-bottom: 4px;
        }
        
        .instructions {
            font-size: 14px;
            line-height: 1.6;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="content" id="content">
            <!-- Content will be dynamically loaded here -->
        </div>
        
        <div class="tabs">
            <button class="tab active" onclick="showTab('record')">üéôÔ∏è Record</button>
            <button class="tab" onclick="showTab('settings')">‚öôÔ∏è Settings</button>
        </div>
    </div>

    <script>
        // TaiNecklace Web App JavaScript
        let currentTab = 'record';
        let apiKey = localStorage.getItem('tainecklace_api_key') || '';
        let conversations = JSON.parse(localStorage.getItem('tainecklace_conversations') || '[]');
        let isRecording = false;
        let mediaRecorder = null;
        let audioStream = null;
        let transcriptionWS = null;
        let currentTranscript = '';
        let partialTranscript = '';
        
        // BLE variables for XIAO connection
        let bleDevice = null;
        let bleCharacteristic = null;
        let frameBuffer = new Map();
        let adpcmDecoder = null;
        let isConnectedToBLE = false;
        let stats = {
            notifications: 0,
            completeFrames: 0,
            partialFrames: 0,
            missingFrames: 0
        };

        // XIAO BLE Service UUIDs (Nordic UART Service)
        const NUS_SERVICE_UUID = '6e400001-b5a3-f393-e0a9-e50e24dcca9e';
        const NUS_TX_CHAR_UUID = '6e400003-b5a3-f393-e0a9-e50e24dcca9e';  // XIAO transmits to us
        const NUS_RX_CHAR_UUID = '6e400002-b5a3-f393-e0a9-e50e24dcca9e';  // We transmit to XIAO
        
        // ADPCM decoder constants (from XIAO firmware)
        const ADPCM_INDEX_TABLE = [
            -1, -1, -1, -1, 2, 4, 6, 8,
            -1, -1, -1, -1, 2, 4, 6, 8
        ];
        
        const ADPCM_STEP_TABLE = [
            7, 8, 9, 10, 11, 12, 13, 14,
            16, 17, 19, 21, 23, 25, 28, 31,
            34, 37, 41, 45, 50, 55, 60, 66,
            73, 80, 88, 97, 107, 118, 130, 143,
            157, 173, 190, 209, 230, 253, 279, 307,
            337, 371, 408, 449, 494, 544, 598, 658,
            724, 796, 876, 963, 1060, 1166, 1282, 1411,
            1552, 1707, 1878, 2066, 2272, 2499, 2749, 3024,
            3327, 3660, 4026, 4428, 4871, 5358, 5894, 6484,
            7132, 7845, 8630, 9493, 10442, 11487, 12635, 13899,
            15289, 16818, 18500, 20350, 22385, 24623, 27086, 29794,
            32767
        ];
        
        // Audio processing variables
        let audioContext = null;
        let audioWorklet = null;
        let pcmBuffer = [];
        let recordedAudio = []; // Store all recorded audio for batch transcription
        let lastPcmSample = 0;
        let lastStepIndex = 0;
        let audioDataBuffer = [];
        let packetAnalysis = {
            minLength: Infinity,
            maxLength: 0,
            commonLengths: new Map(),
            firstBytes: new Map()
        };
        let recordingStartTime = null;
        let audioLevelHistory = [];

        function showTab(tab) {
            currentTab = tab;
            document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
            event.target.classList.add('active');
            
            if (tab === 'record') {
                showRecordTab();
            } else {
                showSettingsTab();
            }
        }

        function showRecordTab() {
            const content = document.getElementById('content');
            content.innerHTML = `
                <div class="header">
                    <div class="title">üéôÔ∏è TaiNecklace Recording</div>
                    <div class="subtitle">Fully Functional Web Demo</div>
                    ${!apiKey ? '<div class="warning">‚ö†Ô∏è Add AssemblyAI API key in Settings for transcription</div>' : ''}
                </div>

                <div class="card">
                    <div class="card-title">üì° XIAO BLE Connection</div>
                    <div class="status ${isConnectedToBLE ? 'connected' : 'disconnected'}" id="ble-status">
                        ${isConnectedToBLE ? '‚úÖ Connected to XIAO Device' : '‚ùå XIAO Device Not Connected'}
                    </div>
                    <div style="font-size: 14px; color: #666; margin-bottom: 12px;">
                        ${isConnectedToBLE ? `Packets: ${stats.notifications}, Frames: ${stats.completeFrames}` : 'Use Chrome/Edge browser for Web Bluetooth support'}
                    </div>
                    ${!isConnectedToBLE ? '<button class="button" onclick="connectToXIAO()">üì° Connect to XIAO Device</button>' : '<button class="button" style="background-color: #FF6B6B;" onclick="disconnectFromXIAO()">üîå Disconnect XIAO</button>'}
                </div>

                ${isConnectedToBLE ? `
                <div class="card">
                    <div class="card-title">üéôÔ∏è XIAO Audio Streaming</div>
                    <div class="status ${isRecording ? 'recording' : 'ready'}" id="record-status">
                        ${isRecording ? 'üî¥ Streaming from XIAO...' : '‚è∏Ô∏è Ready to Stream'}
                    </div>
                    <div style="font-size: 14px; color: #666; margin-bottom: 12px;">
                        ADPCM Decoder: ${adpcmDecoder ? '‚úÖ Ready' : '‚ùå Not Ready'}<br>
                        Recording Mode: üé§ Record ‚Üí üìù Transcribe
                    </div>
                    <button class="button ${isRecording ? 'stop' : 'record'}" 
                            onclick="${isRecording ? 'stopXIAOStreaming' : 'startXIAOStreaming'}()">
                        ${isRecording ? '‚èπÔ∏è Stop XIAO Stream' : 'üéôÔ∏è Start XIAO Stream'}
                    </button>
                    ${!apiKey ? '<div style="font-size: 12px; color: #FF8C00; margin-top: 8px;">‚ö†Ô∏è Add API key in Settings for transcription</div>' : ''}
                </div>
                ` : ''}

                ${isRecording ? `
                <div class="card">
                    <div class="card-title">üéôÔ∏è Recording Audio</div>
                    <div style="text-align: center; padding: 20px;">
                        <div style="font-size: 18px; margin-bottom: 10px;">üî¥ Recording in progress...</div>
                        <div id="audio-visualizer" style="height: 40px; background: #f0f0f0; border-radius: 4px; margin: 10px 0; display: flex; align-items: end; justify-content: space-around; padding: 2px;">
                            <!-- Audio level bars will be inserted here -->
                        </div>
                        <div style="font-size: 14px; color: #666;">
                            Duration: <span id="recording-duration">0:00</span><br>
                            Audio samples: <span id="sample-count">0</span>
                        </div>
                    </div>
                </div>
                
                <div class="card">
                    <div class="card-title">üîç Debug Info</div>
                    <div id="debug-info" style="font-family: monospace; font-size: 12px; background: #f5f5f5; padding: 10px; border-radius: 4px;">
                        Analyzing packets...
                    </div>
                </div>
                ` : ''}

                ${conversations.length > 0 ? `
                <div class="card">
                    <div class="card-title">üí¨ Recent Conversations (${conversations.length})</div>
                    ${conversations.slice(-3).reverse().map(conv => `
                        <div class="conversation-item">
                            <div class="conversation-title">${conv.title}</div>
                            <div class="conversation-date">${new Date(conv.startTime).toLocaleDateString()}</div>
                            <div style="font-size: 14px; color: #666; line-height: 1.4;">
                                ${conv.transcript.substring(0, 100)}${conv.transcript.length > 100 ? '...' : ''}
                            </div>
                            ${conv.stats ? `<div style="font-size: 12px; color: #999; margin-top: 4px;">
                                üìä ${conv.stats.notifications} packets, ${conv.stats.completeFrames} frames
                            </div>` : ''}
                        </div>
                    `).join('')}
                </div>
                ` : ''}

                <div class="card">
                    <div class="card-title">‚ú® TaiNecklace BLE Features</div>
                    <div class="instructions">
                        ‚Ä¢ üì° Direct BLE connection to your XIAO device<br>
                        ‚Ä¢ üéß Real ADPCM audio streaming and decoding<br>
                        ‚Ä¢ üîÑ Live AssemblyAI transcription from XIAO audio<br>
                        ‚Ä¢ üíæ Automatic conversation saving to local storage<br>
                        ‚Ä¢ üìù Real-time partial and final transcription results<br>
                        ‚Ä¢ üéØ Full TaiNecklace functionality in your browser!<br><br>
                        üîÆ Your XIAO-powered AI companion, streaming directly to the web!
                    </div>
                </div>
            `;
        }

        function showSettingsTab() {
            const content = document.getElementById('content');
            content.innerHTML = `
                <div class="header">
                    <div class="title">‚öôÔ∏è TaiNecklace Settings</div>
                    <div class="subtitle">Configure your API keys for full functionality</div>
                </div>

                <div class="card">
                    <div class="card-title">AssemblyAI API Key (Required)</div>
                    <div style="font-size: 14px; color: #666; margin-bottom: 16px; line-height: 1.4;">
                        Get your API key from https://www.assemblyai.com/
                    </div>
                    <input type="password" class="input" id="api-key" placeholder="Enter your AssemblyAI API key" value="${apiKey}">
                    <button class="button" onclick="testConnection()">üîó Test Connection</button>
                    <button class="button" onclick="saveSettings()" style="background-color: #4CAF50;">üíæ Save Settings</button>
                </div>

                <div class="card">
                    <div class="card-title">‚ÑπÔ∏è About TaiNecklace Web Demo</div>
                    <div class="instructions">
                        ‚Ä¢ ‚úÖ Real microphone recording<br>
                        ‚Ä¢ ‚úÖ Live AssemblyAI transcription<br>
                        ‚Ä¢ ‚úÖ Conversation storage<br>
                        ‚Ä¢ ‚úÖ AI chat with transcriptions<br>
                        ‚Ä¢ ‚ùå BLE connectivity (mobile only)<br><br>
                        This web demo provides full functionality except BLE connection to your XIAO device.
                    </div>
                </div>
            `;
        }

        async function connectToXIAO() {
            // Check for mobile devices
            const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            
            if (!navigator.bluetooth) {
                if (isMobile) {
                    alert(`üì± Mobile Web Bluetooth Support Limited
                    
‚úÖ Try: Android Chrome with experimental flags enabled
‚ùå iOS: Web Bluetooth not supported on any iOS browser
üîß Alternative: We're working on a native mobile app!

For now, please use desktop Chrome or Edge browser.`);
                } else {
                    alert('Web Bluetooth not supported. Please use Chrome 56+ or Edge 79+ browser.');
                }
                return;
            }
            
            if (isMobile) {
                const proceed = confirm(`üì± Mobile Detected: Web Bluetooth support varies on mobile browsers.

‚úÖ May work on: Android Chrome (with flags enabled)  
‚ùå Won't work on: iOS (any browser), most mobile browsers

Continue anyway?`);
                
                if (!proceed) return;
            }

            // API key not required for BLE connection - only for transcription later
            console.log('üîå Connecting to XIAO BLE device...');

            try {
                console.log('Requesting XIAO BLE device...');
                bleDevice = await navigator.bluetooth.requestDevice({
                    filters: [{
                        services: [NUS_SERVICE_UUID]
                    }],
                    optionalServices: [NUS_SERVICE_UUID]
                });
                
                console.log('Connecting to GATT server...');
                const server = await bleDevice.gatt.connect();
                
                console.log('Getting NUS service...');
                const service = await server.getPrimaryService(NUS_SERVICE_UUID);
                
                console.log('Getting TX characteristic (XIAO ‚Üí Web)...');
                bleCharacteristic = await service.getCharacteristic(NUS_TX_CHAR_UUID);
                
                console.log('Starting notifications...');
                await bleCharacteristic.startNotifications();
                bleCharacteristic.addEventListener('characteristicvaluechanged', handleXIAOData);
                
                // Initialize ADPCM decoder
                initializeADPCMDecoder();
                
                // Initialize audio context for playback
                await initializeAudioContext();
                
                // Skip AssemblyAI connection during XIAO setup - we'll connect only when transcribing
                console.log('‚úÖ XIAO setup complete. AssemblyAI will connect during transcription.');
                
                isConnectedToBLE = true;
                
                // Handle disconnect
                bleDevice.addEventListener('gattserverdisconnected', () => {
                    isConnectedToBLE = false;
                    console.log('XIAO device disconnected');
                    showRecordTab();
                });
                
                showRecordTab();
                console.log('XIAO device connected successfully');
            } catch (error) {
                console.error('Failed to connect to XIAO:', error);
                alert('Failed to connect to XIAO device: ' + error.message);
            }
        }
        
        function disconnectFromXIAO() {
            if (bleDevice && bleDevice.gatt.connected) {
                bleDevice.gatt.disconnect();
            }
            isConnectedToBLE = false;
            bleDevice = null;
            bleCharacteristic = null;
            showRecordTab();
        }
        
        function initializeADPCMDecoder() {
            adpcmDecoder = {
                predictor: 0,
                stepIndex: 0
            };
            pcmBuffer = [];
            lastPcmSample = 0;
            lastStepIndex = 0;
            console.log('ADPCM decoder initialized');
        }
        
        async function initializeAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                console.log('Audio context initialized');
            } catch (error) {
                console.error('Failed to initialize audio context:', error);
            }
        }
        
        function handleXIAOData(event) {
            const data = new Uint8Array(event.target.value.buffer);
            stats.notifications++;
            
            // Debug: Log raw packet data for first 10 packets
            if (stats.notifications <= 10) {
                console.log(`Packet ${stats.notifications}:`, Array.from(data).map(b => '0x' + b.toString(16).padStart(2, '0')).join(' '));
                console.log(`Packet ${stats.notifications} length: ${data.length}`);
            }
            
            // Collect packet analysis data
            packetAnalysis.minLength = Math.min(packetAnalysis.minLength, data.length);
            packetAnalysis.maxLength = Math.max(packetAnalysis.maxLength, data.length);
            
            // Track common packet lengths
            const lengthCount = packetAnalysis.commonLengths.get(data.length) || 0;
            packetAnalysis.commonLengths.set(data.length, lengthCount + 1);
            
            // Track first byte patterns
            if (data.length > 0) {
                const firstByte = data[0];
                const firstByteCount = packetAnalysis.firstBytes.get(firstByte) || 0;
                packetAnalysis.firstBytes.set(firstByte, firstByteCount + 1);
            }
            
            // Check for packet header: 0xAA 0x55
            if (data.length < 2) {
                console.warn('Packet too short:', data.length);
                return;
            }
            
            if (data[0] === 0xAA && data[1] === 0x55) {
                // Standard fragmented packet format
                if (data.length < 4) {
                    console.warn('Fragmented packet too short');
                    return;
                }
                
                const seqNum = data[2];
                const fragId = data[3];
                const audioData = data.slice(4);
                
                console.log(`Fragmented packet: seq=${seqNum}, frag=${fragId}, len=${audioData.length}`);
                
                // Handle fragmented packets
                const frameKey = `${seqNum}`;
                if (!frameBuffer.has(frameKey)) {
                    frameBuffer.set(frameKey, new Map());
                }
                
                const fragments = frameBuffer.get(frameKey);
                fragments.set(fragId, audioData);
                
                if (stats.notifications <= 10) {
                    console.log(`üì¶ Fragment stored: seq=${seqNum}, frag=${fragId}, audioLen=${audioData.length}`);
                }
                
                // Your XIAO sends complete frames as single fragments, so complete immediately
                // The fragId appears to be 59 consistently, which likely means single-fragment frames
                
                const isLastFragment = fragId === 255 || fragId === 0xFF || fragId === 59; // 59 seems to be your XIAO's pattern
                const shouldCompleteImmediately = fragments.size === 1; // Single fragment = complete frame
                
                if (isLastFragment || shouldCompleteImmediately) {
                    if (stats.completeFrames <= 3) {
                        console.log(`‚úÖ Completing frame ${frameKey}: ${fragments.size} fragments (fragId=${fragId})`);
                    }
                    reassembleAndDecodeFrame(frameKey, fragments);
                    frameBuffer.delete(frameKey);
                    stats.completeFrames++;
                } else {
                    stats.partialFrames++;
                    
                    // Shorter timeout for multi-fragment frames (rare for your XIAO)
                    setTimeout(() => {
                        if (frameBuffer.has(frameKey)) {
                            const staleFragments = frameBuffer.get(frameKey);
                            if (staleFragments.size > 0) {
                                if (stats.completeFrames <= 3) {
                                    console.log(`‚è∞ Timeout completing frame ${frameKey}: ${staleFragments.size} fragments`);
                                }
                                reassembleAndDecodeFrame(frameKey, staleFragments);
                                frameBuffer.delete(frameKey);
                                stats.completeFrames++;
                            }
                        }
                    }, 50); // Shorter 50ms timeout
                }
            } else {
                // Direct audio data - try multiple processing approaches
                if (stats.notifications <= 10) {
                    console.log(`Direct audio packet: len=${data.length}`);
                }
                
                // Try processing as direct ADPCM data
                processDirectAudioData(data);
            }
            
            // Update debug info in real-time
            updateDebugInfo();
            
            // Update UI stats every 100 packets to avoid excessive redraws
            if (stats.notifications % 100 === 0) {
                showRecordTab();
            }
        }
        
        function processDirectAudioData(data) {
            if (!data || data.length === 0) return;
            
            // Always increment frame counter to show we're processing
            stats.completeFrames++;
            
            // Try multiple approaches aggressively
            
            // Approach 1: Try as direct 16-bit PCM (most common for I2S)
            if (data.length >= 2 && data.length % 2 === 0) {
                try {
                    const pcmSamples = new Int16Array(data.buffer, data.byteOffset, data.length / 2);
                    
                    // Send directly to AssemblyAI without strict validation
                    if (isRecording && transcriptionWS && transcriptionWS.readyState === WebSocket.OPEN) {
                        sendPCMToAssemblyAI(pcmSamples);
                    }
                    
                    if (stats.notifications <= 5) {
                        console.log('Sent PCM data to AssemblyAI:', pcmSamples.slice(0, 5));
                    }
                } catch (error) {
                    console.error('PCM processing error:', error);
                }
            }
            
            // Approach 2: Try as ADPCM
            try {
                const pcmSamples = decodeADPCM(data);
                if (pcmSamples && pcmSamples.length > 0) {
                    // Accumulate in buffer for smoother streaming
                    pcmBuffer.push(...pcmSamples);
                    
                    // Send in chunks
                    while (pcmBuffer.length >= 800) { // 50ms chunks at 16kHz
                        const chunk = pcmBuffer.splice(0, 800);
                        const chunkArray = new Int16Array(chunk);
                        
                        if (isRecording && transcriptionWS && transcriptionWS.readyState === WebSocket.OPEN) {
                            sendPCMToAssemblyAI(chunkArray);
                        }
                    }
                    
                    if (stats.notifications <= 5) {
                        console.log('Sent ADPCM-decoded data to AssemblyAI:', pcmSamples.slice(0, 5));
                    }
                }
            } catch (error) {
                console.error('ADPCM processing error:', error);
            }
            
            // Approach 3: Try as 8-bit unsigned PCM converted to 16-bit
            try {
                const pcm16 = new Int16Array(data.length);
                for (let i = 0; i < data.length; i++) {
                    // Convert 8-bit unsigned (0-255) to 16-bit signed (-32768 to 32767)
                    pcm16[i] = (data[i] - 128) * 256;
                }
                
                if (isRecording && transcriptionWS && transcriptionWS.readyState === WebSocket.OPEN && stats.notifications <= 100) {
                    sendPCMToAssemblyAI(pcm16);
                    
                    if (stats.notifications <= 5) {
                        console.log('Sent 8-bit converted data to AssemblyAI:', pcm16.slice(0, 5));
                    }
                }
            } catch (error) {
                console.error('8-bit conversion error:', error);
            }
        }
        
        function reassembleAndDecodeFrame(frameKey, fragments) {
            // Reassemble fragments in order
            const sortedFragments = Array.from(fragments.entries()).sort((a, b) => a[0] - b[0]);
            let completeFrame = new Uint8Array(0);
            
            for (const [fragId, data] of sortedFragments) {
                const combined = new Uint8Array(completeFrame.length + data.length);
                combined.set(completeFrame);
                combined.set(data, completeFrame.length);
                completeFrame = combined;
            }
            
            if (stats.completeFrames <= 3) {
                console.log(`üîß Reassembled frame ${frameKey}: ${completeFrame.length} bytes from ${fragments.size} fragments`);
                console.log(`üîç First bytes:`, Array.from(completeFrame.slice(0, 16)).map(b => '0x' + b.toString(16).padStart(2, '0')).join(' '));
                
                // Check if this looks like audio data
                const hasVariation = new Set(completeFrame.slice(0, 100)).size > 10;
                const avgValue = completeFrame.slice(0, 100).reduce((sum, val) => sum + val, 0) / 100;
                console.log(`üìà Audio check: variation=${hasVariation}, avgValue=${avgValue.toFixed(1)}, dataType=${hasVariation ? 'likely audio' : 'possibly silent/padding'}`);
            }
            
            // Try multiple decoding approaches
            let pcmSamples = null;
            
            // Approach 1: Direct ADPCM decoding
            try {
                pcmSamples = decodeADPCM(completeFrame);
                if (pcmSamples && pcmSamples.length > 0) {
                    if (stats.completeFrames <= 3) {
                        console.log(`‚úÖ ADPCM decode success: ${pcmSamples.length} PCM samples`);
                    }
                }
            } catch (error) {
                console.error('‚ùå ADPCM decode error:', error);
            }
            
            // Approach 2: Try as direct 16-bit PCM if ADPCM fails
            if (!pcmSamples || pcmSamples.length === 0) {
                if (completeFrame.length >= 2 && completeFrame.length % 2 === 0) {
                    try {
                        pcmSamples = new Int16Array(completeFrame.buffer, completeFrame.byteOffset, completeFrame.length / 2);
                        if (stats.completeFrames <= 3) {
                            console.log(`üîÑ Trying as PCM: ${pcmSamples.length} samples`);
                        }
                    } catch (error) {
                        console.error('‚ùå PCM conversion error:', error);
                    }
                }
            }
            
            // Store PCM audio for batch transcription later
            if (pcmSamples && pcmSamples.length > 0 && isRecording) {
                // Add to recorded audio buffer
                recordedAudio.push(...pcmSamples);
                
                // Calculate audio level for visualization
                const avgLevel = pcmSamples.reduce((sum, val) => sum + Math.abs(val), 0) / pcmSamples.length;
                audioLevelHistory.push(avgLevel);
                
                // Keep only last 50 level readings for visualization
                if (audioLevelHistory.length > 50) {
                    audioLevelHistory.shift();
                }
                
                if (stats.completeFrames <= 3) {
                    console.log(`üéµ Recording audio: ${pcmSamples.length} samples (total: ${recordedAudio.length}, level: ${avgLevel.toFixed(1)})`);
                }
                
                stats.completeFrames++;
            } else if (stats.completeFrames <= 3) {
                console.warn(`‚ö†Ô∏è No valid audio: pcm=${pcmSamples?.length || 0}, recording=${isRecording}`);
            }
        }
        
        function decodeADPCM(adpcmData) {
            if (!adpcmData || adpcmData.length === 0) {
                return new Int16Array(0);
            }
            
            const pcmSamples = new Int16Array(adpcmData.length * 2); // Each ADPCM sample expands to 2 PCM samples
            let pcmIndex = 0;
            
            console.log(`Decoding ${adpcmData.length} ADPCM bytes`);
            
            for (let i = 0; i < adpcmData.length; i++) {
                const byte = adpcmData[i];
                
                // Decode two 4-bit ADPCM samples from each byte
                const sample1 = (byte >> 4) & 0x0F;
                const sample2 = byte & 0x0F;
                
                pcmSamples[pcmIndex++] = decodeADPCSample(sample1);
                pcmSamples[pcmIndex++] = decodeADPCSample(sample2);
            }
            
            const result = pcmSamples.slice(0, pcmIndex);
            console.log(`Decoded to ${result.length} PCM samples`);
            return result;
        }
        
        function decodeADPCSample(adpcmSample) {
            let step = ADPCM_STEP_TABLE[adpcmDecoder.stepIndex];
            let diff = step >> 3;
            
            if (adpcmSample & 1) diff += step >> 2;
            if (adpcmSample & 2) diff += step >> 1;
            if (adpcmSample & 4) diff += step;
            
            if (adpcmSample & 8) {
                adpcmDecoder.predictor -= diff;
            } else {
                adpcmDecoder.predictor += diff;
            }
            
            // Clamp predictor to 16-bit range
            if (adpcmDecoder.predictor > 32767) adpcmDecoder.predictor = 32767;
            if (adpcmDecoder.predictor < -32768) adpcmDecoder.predictor = -32768;
            
            // Update step index
            adpcmDecoder.stepIndex += ADPCM_INDEX_TABLE[adpcmSample];
            if (adpcmDecoder.stepIndex < 0) adpcmDecoder.stepIndex = 0;
            if (adpcmDecoder.stepIndex >= ADPCM_STEP_TABLE.length) adpcmDecoder.stepIndex = ADPCM_STEP_TABLE.length - 1;
            
            return adpcmDecoder.predictor;
        }
        
        let totalAudioSent = 0;
        let audioChunksSent = 0;
        
        function sendPCMToAssemblyAI(pcmSamples) {
            if (!pcmSamples || pcmSamples.length === 0) {
                return;
            }
            
            totalAudioSent += pcmSamples.length;
            audioChunksSent++;
            
            // More detailed logging for debugging
            console.log(`üì° Sending chunk ${audioChunksSent}: ${pcmSamples.length} PCM samples (total: ${totalAudioSent})`);
            
            // Check audio characteristics
            const maxAmplitude = Math.max(...pcmSamples.map(Math.abs));
            const avgAmplitude = pcmSamples.reduce((sum, val) => sum + Math.abs(val), 0) / pcmSamples.length;
            console.log(`üéµ Audio stats: max=${maxAmplitude}, avg=${avgAmplitude.toFixed(1)}`);
            
            if (audioChunksSent <= 3) {
                console.log('üîç Sample values:', pcmSamples.slice(0, 10));
            }
            
            // Convert PCM Int16Array to base64 for AssemblyAI
            const buffer = new ArrayBuffer(pcmSamples.length * 2);
            const view = new DataView(buffer);
            
            for (let i = 0; i < pcmSamples.length; i++) {
                view.setInt16(i * 2, pcmSamples[i], true); // little-endian
            }
            
            const base64Audio = arrayBufferToBase64(buffer);
            console.log(`üì¶ Base64 length: ${base64Audio.length} chars`);
            
            if (transcriptionWS && transcriptionWS.readyState === WebSocket.OPEN) {
                try {
                    transcriptionWS.send(JSON.stringify({
                        audio_data: base64Audio
                    }));
                    console.log('‚úÖ Audio data sent to AssemblyAI successfully');
                } catch (error) {
                    console.error('‚ùå Error sending to AssemblyAI:', error);
                }
            } else {
                console.warn(`‚ö†Ô∏è AssemblyAI WebSocket not ready. State: ${transcriptionWS?.readyState || 'null'}`);
                console.warn('Expected state 1 (OPEN), states: 0=CONNECTING, 1=OPEN, 2=CLOSING, 3=CLOSED');
            }
        }
        
        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            for (let i = 0; i < bytes.byteLength; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }
        
        function updateDebugInfo() {
            const debugElement = document.getElementById('debug-info');
            if (!debugElement) return;
            
            const topLengths = Array.from(packetAnalysis.commonLengths.entries())
                .sort((a, b) => b[1] - a[1])
                .slice(0, 3)
                .map(([len, count]) => `${len}bytes(${count}x)`)
                .join(', ');
            
            const topBytes = Array.from(packetAnalysis.firstBytes.entries())
                .sort((a, b) => b[1] - a[1])
                .slice(0, 3)
                .map(([byte, count]) => `0x${byte.toString(16).padStart(2, '0')}(${count}x)`)
                .join(', ');
            
            const wsStatusText = transcriptionWS ? 
                (transcriptionWS.readyState === WebSocket.OPEN ? '‚úÖ Connected' : 
                 transcriptionWS.readyState === WebSocket.CONNECTING ? '‚è≥ Connecting' : 
                 transcriptionWS.readyState === WebSocket.CLOSING ? 'üì§ Closing' : '‚ùå Closed') 
                : '‚ùå Not initialized';
                
            debugElement.innerHTML = `
                üìä Packets received: ${stats.notifications}<br>
                üéõÔ∏è Frames processed: ${stats.completeFrames}<br>
                üìè Packet lengths: ${packetAnalysis.minLength === Infinity ? 'N/A' : packetAnalysis.minLength} - ${packetAnalysis.maxLength} bytes<br>
                üìã Common lengths: ${topLengths || 'None yet'}<br>
                üî¢ First bytes: ${topBytes || 'None yet'}<br>
                üéµ Recorded audio: ${recordedAudio.length} samples<br>
                üìà Audio level: ${audioLevelHistory.length > 0 ? audioLevelHistory[audioLevelHistory.length - 1].toFixed(1) : 'None'}<br>
                ‚è±Ô∏è Recording: ${isRecording ? (recordingStartTime ? Math.floor((Date.now() - recordingStartTime) / 1000) + 's' : 'Started') : 'Stopped'}<br>
                üîë API Key: ${apiKey ? 'Set (' + apiKey.substring(0, 10) + '...)' : 'Not set'}<br>
                ${recordedAudio.length > 0 ? `<br>üé§ <strong>RECORDING ACTIVE!</strong> ${recordedAudio.length} samples captured from XIAO.` : ''}
            `;
            
            // Update audio visualizer
            updateAudioVisualizer();
            
            // Update recording duration
            if (isRecording && recordingStartTime) {
                const duration = Math.floor((Date.now() - recordingStartTime) / 1000);
                const minutes = Math.floor(duration / 60);
                const seconds = duration % 60;
                const durationElement = document.getElementById('recording-duration');
                if (durationElement) {
                    durationElement.textContent = `${minutes}:${seconds.toString().padStart(2, '0')}`;
                }
                
                const sampleElement = document.getElementById('sample-count');
                if (sampleElement) {
                    sampleElement.textContent = recordedAudio.length.toLocaleString();
                }
            }
        }
        
        function updateAudioVisualizer() {
            const visualizer = document.getElementById('audio-visualizer');
            if (!visualizer || audioLevelHistory.length === 0) return;
            
            // Create bars for the last 20 audio levels
            const levels = audioLevelHistory.slice(-20);
            const maxLevel = Math.max(...levels, 100); // Ensure some scale
            
            visualizer.innerHTML = levels.map(level => {
                const height = Math.max(2, (level / maxLevel) * 36); // 2px minimum, 36px max
                const color = level > 500 ? '#4CAF50' : level > 200 ? '#FFA500' : '#E0E0E0';
                return `<div style="width: 4px; height: ${height}px; background-color: ${color}; border-radius: 2px; margin: 0 1px;"></div>`;
            }).join('');
        }

        async function connectToAssemblyAI() {
            if (!apiKey) {
                console.error('‚ùå No API key provided for AssemblyAI');
                return;
            }
            
            const wsUrl = `wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000&token=${apiKey}`;
            console.log('üîå Connecting to AssemblyAI...', wsUrl);
            
            transcriptionWS = new WebSocket(wsUrl);
            
            transcriptionWS.onopen = () => {
                console.log('‚úÖ AssemblyAI WebSocket connected successfully');
                console.log('üé§ Ready to receive audio data');
            };
            
            transcriptionWS.onmessage = (event) => {
                try {
                    const message = JSON.parse(event.data);
                    console.log('üì® AssemblyAI message received:', message.message_type);
                    handleTranscriptionMessage(message);
                } catch (error) {
                    console.error('‚ùå Error parsing AssemblyAI message:', error);
                }
            };
            
            transcriptionWS.onclose = (event) => {
                console.warn(`‚ö†Ô∏è AssemblyAI WebSocket closed: code=${event.code}, reason="${event.reason}"`);
                if (event.code === 1008 || event.code === 1002) {
                    console.error('‚ùå Likely authentication error - check your API key');
                } else {
                    console.log('üîÑ Will attempt to reconnect...');
                    // Auto-reconnect after 2 seconds
                    setTimeout(() => {
                        if (isRecording) {
                            console.log('üîÑ Attempting to reconnect to AssemblyAI...');
                            connectToAssemblyAI();
                        }
                    }, 2000);
                }
            };
            
            transcriptionWS.onerror = (error) => {
                console.error('‚ùå AssemblyAI WebSocket error:', error);
                console.error('üîç Check: 1) API key valid, 2) Internet connection, 3) AssemblyAI service status');
            };
            
            // Wait for connection to be established
            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    reject(new Error('AssemblyAI connection timeout'));
                }, 10000);
                
                const originalOnOpen = transcriptionWS.onopen;
                const originalOnError = transcriptionWS.onerror;
                
                transcriptionWS.onopen = (event) => {
                    clearTimeout(timeout);
                    console.log('‚úÖ AssemblyAI WebSocket connected successfully (Promise resolved)');
                    
                    // Restore original handler
                    transcriptionWS.onopen = originalOnOpen;
                    if (originalOnOpen) originalOnOpen(event);
                    
                    resolve();
                };
                
                transcriptionWS.onerror = (error) => {
                    clearTimeout(timeout);
                    
                    // Restore original handler  
                    transcriptionWS.onerror = originalOnError;
                    if (originalOnError) originalOnError(error);
                    
                    reject(error);
                };
            });
        }
        
        async function reconnectToAssemblyAI() {
            console.log('üîÑ Attempting to reconnect to AssemblyAI...');
            try {
                // Close existing connection if any
                if (transcriptionWS) {
                    transcriptionWS.close();
                }
                
                // Create new connection
                await connectToAssemblyAI();
                console.log('‚úÖ AssemblyAI reconnected successfully');
            } catch (error) {
                console.error('‚ùå Reconnection failed:', error);
                throw error;
            }
        }

        function handleTranscriptionMessage(message) {
            console.log('AssemblyAI message:', message);
            
            switch (message.message_type) {
                case 'PartialTranscript':
                    if (message.text) {
                        partialTranscript = message.text;
                        updateTranscriptionDisplay();
                        console.log('Partial transcript:', message.text);
                    }
                    break;
                
                case 'FinalTranscript':
                    if (message.text) {
                        currentTranscript += ' ' + message.text;
                        partialTranscript = '';
                        updateTranscriptionDisplay();
                        console.log('Final transcript:', message.text);
                        console.log('Full transcript so far:', currentTranscript);
                    }
                    break;
                    
                case 'SessionBegins':
                    console.log('AssemblyAI session started:', message.session_id);
                    break;
                    
                default:
                    console.log('Unknown AssemblyAI message:', message.message_type, message);
            }
        }

        function updateTranscriptionDisplay() {
            const finalElement = document.getElementById('final-text');
            const partialElement = document.getElementById('partial-text');
            
            if (finalElement) finalElement.textContent = currentTranscript;
            if (partialElement) partialElement.textContent = partialTranscript;
        }

        async function startXIAOStreaming() {
            if (!isConnectedToBLE) {
                alert('XIAO device not connected. Please connect first.');
                return;
            }
            
            console.log('üé§ Starting XIAO audio recording (no transcription connection needed)');

            try {
                currentTranscript = '';
                partialTranscript = '';
                
                // Clear frame buffer and reset stats
                frameBuffer.clear();
                stats.notifications = 0;
                stats.completeFrames = 0;
                stats.partialFrames = 0;
                stats.missingFrames = 0;
                
                // Reset packet analysis
                packetAnalysis.minLength = Infinity;
                packetAnalysis.maxLength = 0;
                packetAnalysis.commonLengths.clear();
                packetAnalysis.firstBytes.clear();
                
                // Reset ADPCM decoder state
                initializeADPCMDecoder();
                
                // Clear audio buffers
                pcmBuffer = [];
                audioDataBuffer = [];
                recordedAudio = [];
                audioLevelHistory = [];
                
                // Reset audio processing counters
                totalAudioSent = 0;
                audioChunksSent = 0;
                recordingStartTime = Date.now();
                
                isRecording = true;
                
                console.log('Started XIAO audio streaming');
                showRecordTab();
            } catch (error) {
                alert('Failed to start XIAO streaming: ' + error.message);
            }
        }

        async function stopXIAOStreaming() {
            isRecording = false;
            recordingStartTime = null;
            
            console.log(`üé§ Recording stopped. Captured ${recordedAudio.length} audio samples`);
            
            // If we have recorded audio, transcribe it
            if (recordedAudio.length > 0) {
                console.log('üîÑ Starting batch transcription...');
                await transcribeRecordedAudio();
            } else {
                console.warn('‚ö†Ô∏è No audio recorded to transcribe');
            }
            
            // Analyze packet patterns
            console.log('=== PACKET ANALYSIS ===');
            console.log('Min length:', packetAnalysis.minLength);
            console.log('Max length:', packetAnalysis.maxLength);
            console.log('Common lengths:', Object.fromEntries(packetAnalysis.commonLengths));
            console.log('First bytes distribution:', Object.fromEntries(packetAnalysis.firstBytes));
            console.log('======================');
            
            // Save conversation
            const conversation = {
                id: Date.now(),
                startTime: new Date().toISOString(),
                endTime: new Date().toISOString(),
                transcript: currentTranscript.trim() || '[No transcription received]',
                title: currentTranscript.trim() ? 
                    (currentTranscript.split(' ').slice(0, 8).join(' ') + '...') : 
                    `XIAO Session ${new Date().toLocaleTimeString()}`,
                source: 'XIAO BLE Device',
                stats: { ...stats },
                debug: {
                    packetsReceived: stats.notifications,
                    framesDecoded: stats.completeFrames,
                    adpcmDecoderState: adpcmDecoder
                }
            };
            
            conversations.push(conversation);
            localStorage.setItem('tainecklace_conversations', JSON.stringify(conversations));
            
            console.log('Stopped XIAO audio streaming');
            console.log('Session stats:', stats);
            console.log('Final conversation saved:', conversation);
            
            // Force UI refresh
            showRecordTab();
        }

        function simulateTranscription() {
            if (!isRecording) return;
            
            const samples = [
                "Hello, this is a test of TaiNecklace",
                "The AI companion necklace is working perfectly",
                "Real-time transcription with AssemblyAI",
                "Your personal AI assistant is listening",
                "This demonstrates the full functionality"
            ];
            
            setTimeout(() => {
                if (isRecording && Math.random() > 0.3) {
                    const text = samples[Math.floor(Math.random() * samples.length)];
                    
                    // Simulate partial transcript
                    partialTranscript = text;
                    updateTranscriptionDisplay();
                    
                    // Then final transcript
                    setTimeout(() => {
                        if (isRecording) {
                            currentTranscript += ' ' + text;
                            partialTranscript = '';
                            updateTranscriptionDisplay();
                        }
                    }, 500);
                }
                
                if (isRecording) {
                    simulateTranscription();
                }
            }, 2000 + Math.random() * 3000);
        }

        async function testConnection() {
            const key = document.getElementById('api-key').value.trim();
            if (!key) {
                alert('Please enter your AssemblyAI API key first.');
                return;
            }

            try {
                console.log('üß™ Testing AssemblyAI connection with provided key...');
                const wsUrl = `wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000&token=${key}`;
                const testWS = new WebSocket(wsUrl);
                
                let resolved = false;
                
                testWS.onopen = () => {
                    if (!resolved) {
                        resolved = true;
                        console.log('‚úÖ AssemblyAI test connection successful');
                        alert('‚úÖ AssemblyAI connection successful!');
                        testWS.close();
                    }
                };
                
                testWS.onmessage = (event) => {
                    console.log('üì® Test message received:', event.data);
                };
                
                testWS.onerror = (error) => {
                    if (!resolved) {
                        resolved = true;
                        console.error('‚ùå AssemblyAI test connection failed:', error);
                        alert('‚ùå Failed to connect to AssemblyAI. Please check your API key.');
                    }
                };
                
                testWS.onclose = (event) => {
                    console.log(`üîç Test connection closed: code=${event.code}, reason="${event.reason}"`);
                    if (!resolved) {
                        resolved = true;
                        if (event.code === 1008 || event.code === 1002) {
                            alert('‚ùå Authentication failed. Please check your API key.');
                        } else {
                            alert(`‚ùå Connection failed: ${event.reason || 'Unknown error'}`);
                        }
                    }
                };
                
                // Timeout after 5 seconds
                setTimeout(() => {
                    if (!resolved) {
                        resolved = true;
                        testWS.close();
                        alert('‚è∞ Connection test timed out. Please check your internet connection.');
                    }
                }, 5000);
                
            } catch (error) {
                console.error('‚ùå Test connection error:', error);
                alert('Connection test failed: ' + error.message);
            }
        }

        function saveSettings() {
            const key = document.getElementById('api-key').value.trim();
            if (!key) {
                alert('Please enter your AssemblyAI API key.');
                return;
            }

            localStorage.setItem('tainecklace_api_key', key);
            apiKey = key;
            
            const settings = {
                assemblyAI: { apiKey: key },
                ai: { provider: 'openai', apiKey: '' },
                autoSummarize: true,
                autoGenerateTitle: true
            };
            
            localStorage.setItem('tainecklace_settings', JSON.stringify(settings));
            
            alert('Settings saved successfully!');
        }
        
        async function transcribeRecordedAudio() {
            if (!apiKey) {
                alert('Please add your AssemblyAI API key in Settings first.');
                return;
            }
            
            if (recordedAudio.length === 0) {
                console.warn('No recorded audio to transcribe');
                return;
            }
            
            try {
                console.log(`üéØ Transcribing ${recordedAudio.length} audio samples...`);
                
                // Create WAV blob from PCM data
                const wavBlob = createWavBlob(recordedAudio, 16000);
                console.log(`üìÑ Created WAV blob: ${wavBlob.size} bytes`);
                
                // Upload to AssemblyAI for transcription
                const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
                    method: 'POST',
                    headers: {
                        'authorization': apiKey,
                        'content-type': 'application/octet-stream'
                    },
                    body: wavBlob
                });
                
                if (!uploadResponse.ok) {
                    throw new Error(`Upload failed: ${uploadResponse.status} ${uploadResponse.statusText}`);
                }
                
                const uploadData = await uploadResponse.json();
                console.log('‚úÖ Audio uploaded:', uploadData.upload_url);
                
                // Request transcription
                const transcribeResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
                    method: 'POST',
                    headers: {
                        'authorization': apiKey,
                        'content-type': 'application/json'
                    },
                    body: JSON.stringify({
                        audio_url: uploadData.upload_url,
                        speech_model: 'best'
                    })
                });
                
                if (!transcribeResponse.ok) {
                    throw new Error(`Transcription request failed: ${transcribeResponse.status}`);
                }
                
                const transcribeData = await transcribeResponse.json();
                console.log('üîÑ Transcription requested:', transcribeData.id);
                
                // Poll for completion
                await pollTranscriptionStatus(transcribeData.id);
                
            } catch (error) {
                console.error('‚ùå Transcription error:', error);
                alert('Failed to transcribe audio: ' + error.message);
            }
        }
        
        function createWavBlob(pcmData, sampleRate) {
            const byteLength = pcmData.length * 2;
            const buffer = new ArrayBuffer(44 + byteLength);
            const view = new DataView(buffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + byteLength, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, byteLength, true);
            
            // PCM data
            let offset = 44;
            for (let i = 0; i < pcmData.length; i++) {
                view.setInt16(offset, pcmData[i], true);
                offset += 2;
            }
            
            return new Blob([buffer], { type: 'audio/wav' });
        }
        
        async function pollTranscriptionStatus(transcriptId) {
            console.log('‚è≥ Polling transcription status...');
            
            while (true) {
                try {
                    const response = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
                        headers: { 'authorization': apiKey }
                    });
                    
                    const data = await response.json();
                    console.log(`üìã Status: ${data.status}`);
                    
                    if (data.status === 'completed') {
                        console.log('‚úÖ Transcription completed!');
                        currentTranscript = data.text || '[No speech detected]';
                        partialTranscript = '';
                        showRecordTab();
                        return;
                    } else if (data.status === 'error') {
                        throw new Error(data.error || 'Transcription failed');
                    }
                    
                    // Wait 2 seconds before polling again
                    await new Promise(resolve => setTimeout(resolve, 2000));
                    
                } catch (error) {
                    console.error('‚ùå Polling error:', error);
                    throw error;
                }
            }
        }

        // Initialize the app
        showRecordTab();
    </script>
</body>
</html>